# 逻辑回归

逻辑回归是一种广义线性模型，常用于二分类问题。尽管名字中带有“回归”二字，但逻辑回归实际上是一种分类算法。它通过使用逻辑函数（Sigmoid函数）将线性回归的输出映射到一个概率值，从而实现分类任务。

## 逻辑回归的基本原理

逻辑回归模型的核心是将输入特征的线性组合映射到一个介于0和1之间的概率值。其数学表达式如下：

```math
P(y=1|X) = \sigma(W^TX + b)
```

其中：
- `P(y=1|X)` 表示给定输入特征 `X` 时，输出为1的概率
- `\sigma` 是逻辑函数，定义为 `\sigma(z) = \frac{1}{1 + e^{-z}}`
- `W` 是权重向量
- `X` 是输入特征向量
- `b` 是偏置项

## 逻辑回归的推理过程

1. **初始化参数**：首先，初始化权重向量 `W` 和偏置项 `b` 为零或随机值。
2. **计算线性组合**：对于每个输入特征向量 `X`，计算线性组合 `z = W^TX + b`。
3. **应用逻辑函数**：将线性组合 `z` 通过逻辑函数 `\sigma(z)` 映射到概率值 `P(y=1|X)`。
4. **计算损失函数**：使用交叉熵损失函数来衡量模型预测值与实际值之间的差异。损失函数定义为：

```math
L = -\frac{1}{m} \sum_{i=1}^{m} [y^{(i)} \log(\hat{y}^{(i)}) + (1 - y^{(i)}) \log(1 - \hat{y}^{(i)})]
```

其中 `m` 是样本数量，`y^{(i)}` 是第 `i` 个样本的实际标签，`\hat{y}^{(i)}` 是第 `i` 个样本的预测概率。
5. **梯度下降优化**：通过梯度下降算法更新权重 `W` 和偏置项 `b`，以最小化损失函数。更新规则如下：

```math
W := W - \alpha \frac{\partial L}{\partial W}
b := b - \alpha \frac{\partial L}{\partial b}
```

其中 `\alpha` 是学习率。
6. **迭代训练**：重复步骤2到5，直到损失函数收敛或达到预设的迭代次数。
7. **模型预测**：训练完成后，使用训练好的模型对新数据进行预测，输出概率值并根据阈值进行分类。

## 逻辑回归的应用

逻辑回归广泛应用于以下领域：
- 医疗诊断：预测某种疾病的发生概率
- 市场营销：预测客户是否会购买某种产品
- 信用评分：评估借款人违约的风险

## 优点和缺点

### 优点
- 简单易懂，易于实现
- 计算效率高，适用于大规模数据集
- 输出概率值，便于解释和分析

### 缺点
- 只能处理线性可分的数据，无法处理复杂的非线性关系
- 对于多分类问题，需要扩展为多项逻辑回归

## 参考文献

- [Wikipedia: Logistic Regression](https://en.wikipedia.org/wiki/Logistic_regression)
- [Coursera: Machine Learning by Andrew Ng](https://www.coursera.org/learn/machine-learning)
## 代码实例

下面是一个使用Python和`scikit-learn`库实现逻辑回归的简单示例：

```python
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score

# 生成示例数据
X, y = np.random.rand(100, 2), np.random.randint(0, 2, 100)

# 划分训练集和测试集
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# 初始化逻辑回归模型
model = LogisticRegression()

# 训练模型
model.fit(X_train, y_train)

# 预测
y_pred = model.predict(X_test)

# 计算准确率
accuracy = accuracy_score(y_test, y_pred)
print(f'Accuracy: {accuracy:.2f}')
```

在这个示例中，我们首先生成了一些随机数据，然后将其划分为训练集和测试集。接着，我们初始化并训练了一个逻辑回归模型，并使用测试集进行预测，最后计算并输出了模型的准确率。