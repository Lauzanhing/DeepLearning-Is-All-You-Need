**机器学习背景**：上世纪50年代，Arthur Samuel编写了一个西洋棋程序，编程者不是下棋高手，但是这个程序通过自己和自己下了上万局棋，西洋棋水平超过了编程者。也就是说通过不断学习，能成为一个厉害的西洋棋手。



**机器学习定义**

- Tom Mitchell提出：
  - E=the experience of playing many games of checkers
  - T=the task of playing checkers
  - P=the probability that the program will win the next game
  - 计算机程序从经验E中学习任务T，提升性能P
  - 假设电子邮件程序会观察收到的邮件是否被你标记为垃圾邮件，基于被标记的垃圾邮件，电子邮件程序能更好学习如何过滤垃圾邮件。



**监督学习**

- 房价预测问题
  - 横坐标是不同房子的面积，纵坐标是不同房子的价格
  - 假设你朋友有一栋750平方英尺的房子并且希望卖掉，这房子值多少钱？
  - 用直线拟合它，可以预测大概能卖出15万美金
  - 用二次函数拟合，似乎更贴近给出的样本，预测大概能卖20万美元
  - 通过这个例子，我们房子的数据集，告诉计算机多大的面积适合卖多少钱。而这个算法的任务就是生成更多的“正确答案”，就像告诉朋友你的房子大概卖多少钱，这类问题叫做回归问题
  - 回归问题：预测一个连续的输出值
- 乳腺癌肿瘤分类问题
  - 横坐标是肿瘤的大小，纵坐标是恶性或者良性
  - 假设了某人的肿瘤大小，机器需要做的就是估计肿瘤是良性或者恶性的概率
  - 在实际的问题中可能还会和肿瘤密度，肿瘤细胞尺寸的一致性等有关系，也就是不止两个特征，甚至会有无数个特征，在后面我们会提到用支撑向量机去解决这样的问题
- 举例
  - 回归问题：有一大批同样的货物，有上千件一模一样的货物等待出售，预测接下来的三个月的能卖多少（数千件货物我们会看作连续的值，卖出去的数目也是连续的值）
  - 分类问题：有很多的客户，想写一个软件来检验每一个用户的账号，判断是否曾经被盗？（0表示没有被盗，1表示被盗，都只是离散值，所以归为分类问题）



**无监督学习**

-  与监督学习的区别：在监督学习中，我们清楚的知道什么是所谓的正确答案。而在无监督学习中，只有数据，没有所谓的标签和属性，也就是说所有的数据看起来都是一样的
- 无监督学习在做什么：只有数据集，没有人告诉我们应该干什么，每个数据点的意思也不知道，我们要从单纯的数据集中找到其中的某种结构。
- 举例：
  - 新闻的报道网页：当我们点进一篇关于BP油井泄漏事故的报道，我们就能在相关报道中看到一些相关平台的比如CNN/华尔街日报等关于这个BP油井泄漏事故的报道。
  - 基因芯片：不同的这些颜色展示的是这些个体是否拥有一个特定基因的不同程度，聚类算法（无监督学习）就是把他们分成不同类型的人。
  - 鸡尾酒宴问题：在吵杂的鸡尾酒宴会上的两个房间录音，两个人站在距离两支麦克风不同的位置，同样说123456789，虽然会重叠录在一起，但是录音的距离其实不同，我们可以通过算法把两个人的音频分离开来。